{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e41df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.10.12 torch-2.2.2+cu121 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "Setup complete ‚úÖ (80 CPUs, 754.5 GB RAM, 4434.8/4434.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnxruntime\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Local packages\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "      \n",
    "    \n",
    "class Yolov8Detector():\n",
    "\n",
    "    def __init__(self, model_path='best.onnx', size=(640, 640), classes={0: 'face'}, model_name=\"yolov8\") -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MyDetector object.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the model file.\n",
    "            size (tuple): Size of the input image.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "#         self._session = onnxruntime.InferenceSession(model_path)\n",
    "#         self.input_name = self._session.get_inputs()[0].name\n",
    "#         self.output_names = [self._session.get_outputs()[0].name]\n",
    "        self._size = size\n",
    "        self.classes = classes\n",
    "        self.model_name = model_name\n",
    "        self.model = YOLO(model_path, task='detect')\n",
    "    \n",
    "\n",
    "    def video_run(self, cap):\n",
    "        \"\"\"\n",
    "        Process video frames and draw bboxes.\n",
    "\n",
    "        Args:\n",
    "            cap: Video capture object.\n",
    "\n",
    "        Returns:\n",
    "            io.BytesIO: In-memory file containing the processed video.\n",
    "        \"\"\"\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        \n",
    "        # Video stream handling \n",
    "        output_memory_file = io.BytesIO()\n",
    "        output_f = av.open(output_memory_file, 'w', format='mp4')  # Open \"in memory file\" as MP4 video output\n",
    "        stream = output_f.add_stream('h264', str(fps))  # Add H.264 video stream to the MP4 container, with framerate = fps.\n",
    "        stream.width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        stream.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        # Video capturing\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            #find bounding boxes and track them via YOLO model method    \n",
    "            results = self.model.track(frame, device='cpu', persist=True, conf=0.23, iou = 0.8, tracker='bytetrack.yaml')\n",
    "#             results = self.model.predict(frame, conf=0.23 , iou=0.8)\n",
    "            \n",
    "            #draw bboxes\n",
    "            annotated_frame = results[0].plot()\n",
    "#             print(annotated_frame.shape)\n",
    "            # Convert image from NumPy Array to frame.\n",
    "            annotated_frame = av.VideoFrame.from_ndarray(annotated_frame, format='bgr24') \n",
    "            packet = stream.encode(annotated_frame)  # Encode video frame\n",
    "            output_f.mux(packet)  # \"Mux\" the encoded frame (add the encoded frame to MP4 file).\n",
    "            \n",
    "        # Flush the encoder\n",
    "        packet = stream.encode(None)\n",
    "        output_f.mux(packet)\n",
    "        output_f.close()\n",
    "        return output_memory_file\n",
    "    \n",
    "    def draw_box(self, img):\n",
    "        output = self.model.predict(img, device='cpu',  conf= 0.23, iou = 0.8)\n",
    "        output_img = output[0].plot()\n",
    "        return output_img\n",
    "    \n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.draw_box(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb88b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import av\n",
    "from IPython.display import Video\n",
    "# Define the path to the input video file\n",
    "input_video_path = 'video/–ñ–î_–í–æ–∫–∑–∞–ª_11_–ñ–î_–í–æ–∫–∑–∞–ª_11_03_04_2024_08_15_00_03_04_2024_08_35_00.mp4'\n",
    "\n",
    "# Define the path to the output video file\n",
    "output_video_path = 'video/output_video_ZHDvokzal.mp4'\n",
    "\n",
    "# Open the input video file for reading\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Check if the video file was successfully opened\n",
    "if not input_video.isOpened():\n",
    "    print(\"Error: Unable to open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Create an instance of the Yolov8Detector class\n",
    "detector = Yolov8Detector()\n",
    "print(input_video)\n",
    "# Process the video frames and save the processed video\n",
    "with detector.video_run(input_video) as output_memory_file:\n",
    "    with open(output_video_path, \"wb\") as f:\n",
    "        f.write(output_memory_file.getbuffer())\n",
    "\n",
    "# Release the input video file\n",
    "input_video.release()\n",
    "\n",
    "print(\"Video processing complete. Output video saved to:\", output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dacb3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/output_video.mp4\" controls  width=\"1920\"  height=\"1080\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c269d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è 'source' is missing. Using 'source=/workspace/Syrenny/bot_integration/bot_venv/lib/python3.10/site-packages/ultralytics/assets'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1967.082] global loadsave.cpp:248 findDecoder imread_('zidane.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best.onnx for ONNX Runtime inference...\n",
      "\n",
      "image 1/2 /workspace/Syrenny/bot_integration/bot_venv/lib/python3.10/site-packages/ultralytics/assets/bus.jpg: 640x640 2 faces, 59.8ms\n",
      "image 2/2 /workspace/Syrenny/bot_integration/bot_venv/lib/python3.10/site-packages/ultralytics/assets/zidane.jpg: 640x640 2 faces, 60.0ms\n",
      "Speed: 2.5ms preprocess, 59.9ms inference, 19.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "(1080, 810, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞\n",
    "detector = Yolov8Detector()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "image_path = 'zidane.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é\n",
    "result_image = detector(image)\n",
    "\n",
    "result_image= cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "print(result_image.shape)\n",
    "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–æ–º–æ—â—å—é Matplotlib\n",
    "plt.imshow(result_image)\n",
    "plt.savefig('transformed_image.jpg')  # Save the image to a file\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8a08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot_kernel",
   "language": "python",
   "name": "bot_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
