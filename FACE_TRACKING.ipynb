{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face tracking pipeline\n",
    "\n",
    "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install mmcv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uninstall all versions of opencv\n",
    "!pip uninstall $(pip list --format=freeze | grep opencv)\n",
    "!rm -rf /usr/local/lib/python3.10/dist-packages/cv2/\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import numpy as np\n",
    "import mmcv, cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_img(img: np.array, figsize: tuple = (5, 5), savefig: str = None):\n",
    "    \"\"\" \n",
    "    img -> np.array,\n",
    "    figsize -> tuple,\n",
    "    savefig -> str\n",
    "    \"\"\"\n",
    "    if img.size == 0:\n",
    "        print(\" ОШИБКА!!!!!!Массив img пустой, невозможно создать изображение.\")\n",
    "        return\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.imshow(img)\n",
    "    if savefig:\n",
    "        plt.savefig(savefig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(frame: np.array, boxes: np.array):\n",
    "    \"\"\"\n",
    "    Extract images of face from 'frame' with bboxes from 'boxes'\n",
    "    \"\"\"\n",
    "    #x_ranges = [range(*bounds) for bounds in boxes[:, ::2].astype(int)]\n",
    "    #y_ranges = [range(*bounds) for bounds in boxes[:, 1::2].astype(int)]\n",
    "    #faces = [frame[y][:, x] for x, y in zip(x_ranges, y_ranges)]\n",
    "    faces = []\n",
    "    for bounds in boxes:\n",
    "        x_start, x_end, y_start, y_end = bounds.astype(int)\n",
    "        face = frame[y_start:y_end, x_start:x_end]\n",
    "        faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 26 11:53:03 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             153W / 300W |  23403MiB / 32768MiB |     99%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a sample video\n",
    "\n",
    "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video = mmcv.VideoReader('inferenceB.mp4')\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "display.Video('inferenceB.mp4', width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/1.webm\" controls  width=\"640\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = mmcv.VideoReader('./videos/1.webm')\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "display.Video('videos/1.webm', width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735919"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 1349, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run video through MTCNN\n",
    "\n",
    "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking frame: 9271"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "frames_tracked = []\n",
    "center_coordinates_list = []\n",
    "boxes_list = []\n",
    "probs_list = []\n",
    "landmarks_list = []\n",
    "  \n",
    "for i, frame in enumerate(frames[100:]):\n",
    "    print('\\rTracking frame: {}'.format(i), end='')\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs, landmarks = mtcnn.detect(frame, landmarks=True)\n",
    "    \n",
    "    if boxes is not None:\n",
    "        keep = np.where(probs > threshold)\n",
    "        boxes = boxes[keep]\n",
    "        landmarks = landmarks[keep]\n",
    "        center_coordinates = (np.vstack([((boxes[:, 0] + boxes[:, 2])/2), ((boxes[:, 1] + boxes[:, 3])/2)])).astype('int').T\n",
    "    \n",
    "    \n",
    "#     print((boxes.shape[0]))\n",
    "#     for i in range(((boxes.shape[0]))):\n",
    "#         print((int((boxes[i][0]+boxes[i][2])/2), int((boxes[i][2]+boxes[i][3])/2)))\n",
    "#     (frame.show())\n",
    "    \n",
    "        # Draw faces\n",
    "        frame_draw = frame.copy()\n",
    "        draw = ImageDraw.Draw(frame_draw)\n",
    "\n",
    "        for box in boxes:\n",
    "            draw.rectangle(box.tolist(), outline=(255, 0, 0), width=3)\n",
    "        \n",
    "#     for pnt in center_coordinates:    \n",
    "#         draw.rectangle(np.hstack([(pnt-3), (pnt+3)]).tolist(), outline=(255, 0, 0), width=2)\n",
    "    \n",
    "        # Add to frame list\n",
    "        frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
    "        center_coordinates_list.append(center_coordinates)\n",
    "        boxes_list.append(boxes)\n",
    "        probs_list.append(probs)\n",
    "        landmarks_list.append(landmarks)\n",
    "    \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boxes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = extract(np.array(frames[0]), boxes_list[0])\n",
    "\n",
    "faces_list = []\n",
    "faces_list.append(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for j in range(len(center_coordinates_list)-1):\n",
    "    sim_matrix = (distances(center_coordinates_list[j], \n",
    "                            center_coordinates_list[j+1]) <= 64)*1\n",
    "    i_ids, j_ids  = np.nonzero(sim_matrix == 1)\n",
    "    idxs_for_crop = list(set(range(len(center_coordinates_list[j+1]))) - set(j_ids))\n",
    "    \n",
    "    if idxs_for_crop:\n",
    "#         print(boxes_list[j+1])\n",
    "    \n",
    "        faces = extract(np.array(frames[j+1]), np.array(boxes_list[j+1])[idxs_for_crop])\n",
    "        faces_list.append(faces)\n",
    "len(faces_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(faces_list)):\n",
    "    if len(faces_list[i])>0:\n",
    "        for j in range(len(faces_list[i])):\n",
    "#             if faces_list[i][j].shape[1] >=80:\n",
    "                plot_img(faces_list[i][j], \n",
    "                  savefig = f\"./cropped_faces/{i}_{int(boxes_list[i][j][0])}_{int(boxes_list[i][j][1])}.jpg\")\n",
    "                print(f\"./cropped_faces/{i}_{int(boxes_list[i][j][0])}_{int(boxes_list[i][j][1])}.jpg\")\n",
    "                print(\"% вероятности целевого события:  \", probs_list[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = display.display(frames_tracked[0], display_id=True)\n",
    "i = 1\n",
    "for i in range(len(frames_tracked)):\n",
    "        d.update(frames_tracked[i % len(frames_tracked)])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(frames_tracked[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d = display.display(frames_tracked[0], display_id=True)\n",
    "i = 1\n",
    "try:\n",
    "    while True:\n",
    "        d.update(frames_tracked[i % len(frames_tracked)])\n",
    "        i += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tracked video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim = frames_tracked[0].size\n",
    "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
    "video_tracked = cv2.VideoWriter('video_tracked.mp4', fourcc, 25.0, dim)\n",
    "for frame in frames_tracked:\n",
    "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "video_tracked.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
