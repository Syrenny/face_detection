{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "print(model.classes)\n",
    "\n",
    "# Images\n",
    "imgs = Image.open('faces/22.jpg')\n",
    "\n",
    "# Inference\n",
    "results = model([imgs])\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.show()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(results.pandas().xyxy[0])\n",
    "df = pd.DataFrame(results.pandas().xyxy[0])\n",
    "df.drop('name', axis=1, inplace=True)\n",
    "mask = df['class'] != 0\n",
    "df.drop(df[mask].index, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .\n",
    "# !git clone https://github.com/ifzhang/ByteTrack.git\n",
    "# %cd workspace/ByteTrack\n",
    "\n",
    "# # workaround related to https://github.com/roboflow/notebooks/issues/80\n",
    "# !sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
    "\n",
    "# !pip3 install -q -r requirements.txt\n",
    "# !python3 setup.py -q develop\n",
    "# !pip install -q cython_bbox\n",
    "# !pip install -q onemetric\n",
    "# # workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
    "# !pip install -q loguru lap thop\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"/workspace/ByteTrack\")\n",
    "\n",
    "\n",
    "import yolox\n",
    "print(\"yolox.__version__:\", yolox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
    "from onemetric.cv.utils.iou import box_iou_batch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25\n",
    "    track_buffer: int = 30\n",
    "    match_thresh: float = 0.8\n",
    "    aspect_ratio_thresh: float = 3.0\n",
    "    min_box_area: float = 1.0\n",
    "    mot20: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# Tracker\n",
    "# tracker = BYTETracker(None, fps)\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Путь к видеофайлу\n",
    "video_path = 'mp4/Video_example.mp4'  # Замените путь на ваш видеофайл\n",
    "\n",
    "# Загрузка видео\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Создание объекта VideoWriter для записи результата\n",
    "output_path = 'output.mp4'  # Замените путь по своему усмотрению\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Детекция объектов\n",
    "    results = model([frame])\n",
    "    \n",
    "    # Список bboxes, принадлежащих классу 0 ('person')\n",
    "    df = pd.DataFrame(results.pandas().xyxy[0])\n",
    "    df.drop('name', axis=1, inplace=True)\n",
    "    mask = df['class'] != 0\n",
    "    df.drop(df[mask].index, inplace=True)\n",
    "    \n",
    "#     for xmin, ymin, xmax, ymax, confidence, _ in df:\n",
    "#         online_targets = tracker.update(dets, info_imgs, img_size)\n",
    "        \n",
    "    # Отрисовка bounding boxes на изображении\n",
    "    frame_with_boxes = results.render()[0].astype('uint8')\n",
    "    \n",
    "    # Запись кадра с bounding boxes в выходной файл\n",
    "    output.write(frame_with_boxes)\n",
    "\n",
    "    \n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/yoloface/\")\n",
    "from yoloface.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "model = YoloDetector(target_size=720, device=\"cuda:0\", min_face=5)\n",
    "orgimg = np.array(Image.open('faces/22.jpg'))\n",
    "bboxes,points = model.predict(orgimg)\n",
    "\n",
    "# Рисование bounding boxes\n",
    "image = orgimg.copy()\n",
    "for bbox in bboxes[0]:\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "print(bboxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lap\n",
    "import sys\n",
    "sys.path.append(\"/workspace/yoloface/\")\n",
    "import cv2\n",
    "import torch\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "import pandas as pd\n",
    "from yoloface.face_detector import YoloDetector\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "class ByteTrackArgument:\n",
    "    track_thresh = 0.5 # High_threshold\n",
    "    track_buffer = 50 # Number of frame lost tracklets are kept\n",
    "    match_thresh = 0.8 # Matching threshold for first stage linear assignment\n",
    "    aspect_ratio_thresh = 10.0 # Minimum bounding box aspect ratio\n",
    "    min_box_area = 1.0 # Minimum bounding box area\n",
    "    mot20 = False # If used, bounding boxes are not clipped.\n",
    "\n",
    "MIN_THRESHOLD = 0.001\n",
    "\n",
    "# Model\n",
    "model = YoloDetector(target_size=720, device=\"cuda:0\", min_face=80)\n",
    "\n",
    "# Путь к видеофайлу\n",
    "video_path = 'mp4/Video_example.mp4'  # Замените путь на ваш видеофайл\n",
    "\n",
    "# Загрузка видео\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Tracker\n",
    "# tracker = BYTETracker(ByteTrackArgument)\n",
    "\n",
    "# Создание объекта VideoWriter для записи результата\n",
    "output_path = 'output.mp4'  # Замените путь по своему усмотрению\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    # Load the image and convert it to a PIL image\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     frame = Image.fromarray(frame)\n",
    "    # Детекция объектов\n",
    "    bboxes, points = model.predict(frame)\n",
    "    \n",
    "    # Рисование bounding boxes\n",
    "    frame_with_boxes = frame.copy()\n",
    "    for bbox in bboxes[0]:\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        cv2.rectangle(frame_with_boxes, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "    \n",
    "#     for xmin, ymin, xmax, ymax in bboxes[0]:\n",
    "#         online_targets = tracker.update(np.array([[xmin, ymin, xmax, ymax, 1.0]]), [frame_height, frame_width], [frame_height, frame_width])\n",
    "#         print(online_targets)\n",
    "    # Запись кадра с bounding boxes в выходной файл\n",
    "    output.write(frame_with_boxes)\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"output.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Display results ==\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "video_path = \"output.mp4\"\n",
    "\n",
    "mp4 = open(video_path, \"rb\").read()\n",
    "data_url = \"data:video/webm;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=600 controls>\n",
    "      <source src=\"{data_url}\" type=\"video/webm\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracker.byte_tracker import BYTETracker\n",
    "\n",
    "images = \n",
    "tracker = BYTETracker(args)\n",
    "for image in images:\n",
    "   dets = model(image)\n",
    "   online_targets = tracker.update(dets, info_imgs, img_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "face_detection_venv",
   "language": "python",
   "name": "face_detection_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
