{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yoloface.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "model = YoloDetector(target_size=720, device=\"cuda:0\", min_face=5)\n",
    "orgimg = np.array(Image.open('faces/22.jpg'))\n",
    "bboxes,points = model.predict(orgimg)\n",
    "\n",
    "# Рисование bounding boxes\n",
    "image = orgimg.copy()\n",
    "for bbox in bboxes[0]:\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "print(bboxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "import paddle\n",
    "paddle.utils.run_check()\n",
    "\n",
    "# confirm the paddle's version\n",
    "!python -c \"import paddle; print(paddle.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/yoloface/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from yoloface.face_detector import YoloDetector\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Model\n",
    "face_detector = YoloDetector(target_size=720, device=\"cuda:0\", min_face=80)\n",
    "\n",
    "# Путь к видеофайлу\n",
    "video_path = 'mp4/Video_example.mp4'  # Замените путь на ваш видеофайл\n",
    "\n",
    "# Загрузка видео\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Tracker preset:\n",
    "\n",
    "# Embeder parameters:\n",
    "# EMBEDDER_CHOICES = [\n",
    "#     \"mobilenet\",\n",
    "#     \"torchreid\",\n",
    "#     \"clip_RN50\",\n",
    "#     \"clip_RN101\",\n",
    "#     \"clip_RN50x4\",\n",
    "#     \"clip_RN50x16\",\n",
    "#     \"clip_ViT-B/32\",\n",
    "#     \"clip_ViT-B/16\",\n",
    "# ]\n",
    "\n",
    "tracker_params = {\n",
    "    \"max_iou_distance\": 0.7,\n",
    "    \"max_age\": 30,\n",
    "    \"n_init\": 3,\n",
    "    \"nms_max_overlap\": 1.0,\n",
    "    \"max_cosine_distance\": 0.2,\n",
    "    \"nn_budget\": None,\n",
    "    \"gating_only_position\": False,\n",
    "    \"override_track_class\": None,\n",
    "    \"embedder\": \"mobilenet\",\n",
    "    \"half\": True,\n",
    "    \"bgr\": True,\n",
    "    \"embedder_gpu\": True,\n",
    "    \"embedder_model_name\": None,\n",
    "    \"embedder_wts\": None,\n",
    "    \"polygon\": False,\n",
    "    \"today\": None,\n",
    "}\n",
    "\n",
    "# Tracker\n",
    "tracker = DeepSort(**tracker_params)\n",
    "\n",
    "# Создание объекта VideoWriter для записи результата\n",
    "output_path = 'output.mp4'  # Замените путь по своему усмотрению\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Детекция объектов\n",
    "    bboxes, points = face_detector.predict(frame)\n",
    "    \n",
    "    # bboxes in update_tracks expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\n",
    "    bboxes_formatted = []\n",
    "    for xmin, ymin, xmax, ymax in bboxes[0]:\n",
    "        bboxes_formatted.append(([xmin, ymax, xmax - xmin, ymax - ymin], 1.0, 'face'))\n",
    "        \n",
    "    frame_with_boxes = frame.copy()\n",
    "    tracks = tracker.update_tracks(bboxes_formatted, frame=frame) \n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        left, top, right, bottom = track.to_ltrb()\n",
    "        cv2.rectangle(frame_with_boxes, (left, bottom), (right, top), (0, 255, 0), 2)    \n",
    "        \n",
    "    output.write(frame_with_boxes)\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Display results ==\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "video_path = \"output.mp4\"\n",
    "\n",
    "mp4 = open(video_path, \"rb\").read()\n",
    "data_url = \"data:video/webm;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=600 controls>\n",
    "      <source src=\"{data_url}\" type=\"video/webm\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "face_detection_venv",
   "language": "python",
   "name": "face_detection_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
